# Scinetific paper abstractive summarization (Capstone design 2020-2)
## Overview
* 개인적으로 논문을 읽을 때 줄 간격이 좁고 글자 크기가 작아 재빨리 독해를 하는데 어려움을 겪어 논문내용을 요약하여 독해를 도와주는 서비스를 필요로 하게 되었다.
* 서비스의 완성까지는 감당하기 어려운 난이도이므로, 자연어처리 공부에 입문하고 향후 해당 기능을 만드는데 도움이 되도록 text-summarization 모델의 설계를 주제로 하게 되었다.
* 4주차 - sequence to sequence-attention abstractive summarization의 이해
* 5주차 - 데이터셋 탐색과 선택, baseline study (NLP-kr/tensorflow-ml-nlp-tf2를 참조함)
* 6주차 - transformer 모델의 이해, 데이터셋 살펴보기, 대략적인 모델의 설계.


## Schedule
| Contents | March | April |  May  | June  |   Progress   |
|----------|-------|-------|-------|-------|--------------|
|Baseline study|    0   |    0   |       |       |     Link1    |
|  데이터셋 수집  |  0     |   0    |       |       |     Link2    |
|  모델 설계  |       |   0    |    0   |       |     Link3    |
|  중간보고서제출  |       |       |    0   |       |     Link4    |
| 최종보고서제출 |       |      |       |     0  |     Link5    |

## Results
* Main code, table, graph, comparison, ...
* Web link

``` C++
void Example(int x, int y) {
   ...  
   ... // comment
   ...
}
```

## Conclusion
* Summary, contribution, ...

## Reports
