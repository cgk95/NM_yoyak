
>transformer 모델
>> resource exhausted 문제를 batch 사이즈를 극단적으로 줄여서 해결하긴 했는데 학습시간이 너무 오래 걸리게 되어 문제가 있습니다.
구글 코랩에서 학습을 진행 중인데 지금 결과가 나오는 것으로 좀 더 길이가 짧은 데이터셋으로 변경할 것인지, 그대로 진행할 것인지 정하게 될 것 같습니다.

> 모델 튜닝과 평가
> > 사실 lstm-attn을 사용하였을 때와 transfomer 형태를 사용하였을 때의 문제점이 비슷합니다. 타깃문장들을 학습된 모델을 통해 요약하면 뭔가 연관된 단어들이 튀어나오기는 하는데 그것이 문장의 형태, 혹을 문장의 형태가 아니더라도 정보를 얻을 수 있는 형태로 나오지 않는다는 점입니다.
> >  rouge score를 평가하는 법을 배웠고 이를 통해 지금까지 공부해왔던 코드들을 평가하여 보고서에 작성하려 합니다.
